diff --git a/sailreval/joern/cfg/cfged.py b/sailreval/joern/cfg/cfged.py
index eceb9ee..6e32ad8 100644
--- a/sailreval/joern/cfg/cfged.py
+++ b/sailreval/joern/cfg/cfged.py
@@ -1,15 +1,16 @@
 import itertools
 from collections import defaultdict
 from pathlib import Path
-from typing import Dict, Union, List, Set, Optional
+from typing import Dict, Union, List, Set, Optional, Tuple
 import logging
 
 import networkx as nx
 
+from .jil.statement import Nop
 from .region_identifier import RegionIdentifier
 from .graph_region import GraphRegion
 from .ged import graph_edit_distance_core_analysis, MAX_NODES_FOR_EXACT_GED
-from .utils import addr_to_node_map, save_as_png
+from .utils import addr_to_node_map, to_jil_supergraph, node_is_function_start, expand_region_head_to_block, node_is_function_end
 from .jil.block import Block, make_merge_block, MergedRegionStart
 from ...utils.binary_debug_info import gen_dwarf_addr_to_line_map, read_line_maps
 from ...utils import bcolors, timeout
@@ -20,6 +21,12 @@ if _DEBUG:
     l.setLevel(logging.DEBUG)
 
 
+def toggle_debug():
+    global _DEBUG
+    _DEBUG = not _DEBUG
+    l.setLevel(logging.DEBUG if _DEBUG else logging.INFO)
+
+
 def _ged_upperbound_approx(dec_cfg, src_cfg, with_timeout=3):
     try:
         with timeout(seconds=with_timeout):
@@ -32,7 +39,8 @@ def _ged_upperbound_approx(dec_cfg, src_cfg, with_timeout=3):
 
 def find_dst_mismatches(
     dec_edges, src_edges,
-    dec_line_to_addr_map: Dict, src_addr_to_line_map: Dict,
+    dec_line_to_addr_map: Dict,
+    src_addr_to_line_map: Dict,
 ):
     """
     In this algorithm, we always assume the decompiler is the graph we are transforming into the source graph.
@@ -104,6 +112,22 @@ def find_dst_mismatches(
     return total_edits
 
 
+def extra_points_for_func_end_edges(dec_r_cfg, src_r_cfg, dec_succ, src_succ):
+    dec_is_end = node_is_function_end(dec_succ)
+    src_is_end = node_is_function_end(src_succ)
+
+    # in the event that both are either not the end or are the end
+    # then we can depend on GED to handle it normally
+    if not dec_is_end and not src_is_end:
+        return 0
+    elif dec_is_end and src_is_end:
+        return 0
+
+    dec_end_edges = list(dec_r_cfg.predecessors(dec_succ))
+    src_end_edges = list(src_r_cfg.predecessors(src_succ))
+    return len(dec_end_edges) + len(src_end_edges)
+
+
 def destroy_old_region(cfg: nx.DiGraph, expanded_region_graph: nx.DiGraph, r_head: Block):
     extra_edges = defaultdict(list)
     r_nodes = list(expanded_region_graph.nodes)
@@ -135,30 +159,67 @@ def destroy_old_region(cfg: nx.DiGraph, expanded_region_graph: nx.DiGraph, r_hea
     return extra_edges
 
 
-def expand_region_to_block_graph(region: GraphRegion, graph: nx.DiGraph):
-    def _expand_region_to_blocks(_region: GraphRegion):
-        all_nodes = list()
-        for node in _region.graph.nodes:
-            if isinstance(node, Block):
-                all_nodes.append(node)
-            elif isinstance(node, GraphRegion):
-                all_nodes += _expand_region_to_blocks(node)
+def expand_region_to_successor_block_graph(
+    region: GraphRegion, full_graph: nx.DiGraph, include_preds=True, include_succs=True
+) -> Tuple[Optional[nx.DiGraph], Optional[Block]]:
+    # all regions should only every have 1 or None successors
+    if region.successors and len(region.successors) > 1:
+        return None, None
+
+    #
+    # Gather all the blocks inside the region
+    #
+
+    region_blocks = expand_region_to_blocks(region)
+
+    #
+    # Gather every block that has an edge into the region
+    #
+
+    pred_blocks = []
+    if include_preds:
+        for region_block in region_blocks:
+            for pred in full_graph.predecessors(region_block):
+                if pred not in region_blocks:
+                    pred_blocks.append(pred)
+
+    #
+    # Gather every block that has an incoming edge from the region (successors)
+    #
+
+    # should end with a size of just 1
+    successors = []
+    if include_succs and region.successors and region.graph_with_successors:
+        # assumption: the region has only one successor
+        successor = list(region.successors)[0]
+        if isinstance(successor, Block):
+            successor_head = successor
+        elif isinstance(successor, GraphRegion):
+            successor_head = expand_region_head_to_block(successor)
+        else:
+            return None, None
 
-        return all_nodes
+        successors = [successor_head]
+    successor_block = successors[0] if successors else None
 
-    region_blocks = _expand_region_to_blocks(region)
-    return nx.subgraph(graph, region_blocks)
+    return nx.subgraph(full_graph, pred_blocks + region_blocks + successors), successor_block
 
 
-def expand_region_head_to_block(region: GraphRegion):
-    region_head = region.head
-    if isinstance(region_head, Block):
-        return region_head
+def expand_region_to_blocks(_region: GraphRegion):
+    all_nodes = list()
+    for node in _region.graph.nodes:
+        if isinstance(node, Block):
+            all_nodes.append(node)
+        elif isinstance(node, GraphRegion):
+            all_nodes += expand_region_to_blocks(node)
 
-    if isinstance(region_head, GraphRegion):
-        return expand_region_head_to_block(region_head)
+    return all_nodes
+
+
+def expand_region_to_block_graph(region: GraphRegion, graph: nx.DiGraph):
+    region_blocks = expand_region_to_blocks(region)
+    return nx.subgraph(graph, region_blocks)
 
-    raise ValueError(f"Invalid region head type {type(region_head)}")
 
 def is_only_blocks(region: GraphRegion):
     for node in region.graph.nodes:
@@ -227,7 +288,7 @@ def dfs_region_for_leafs(region: GraphRegion):
         yield region
 
 
-def find_some_leaf_region(region: Union[Block, GraphRegion], node_blacklist, og_cfg: nx.DiGraph) -> Optional[Union[GraphRegion, Block]]:
+def find_some_tail_region(region: Union[Block, GraphRegion], node_blacklist, og_cfg: nx.DiGraph) -> Optional[Union[GraphRegion, Block]]:
     # sanity check
     if isinstance(region, Block):
         return region
@@ -262,14 +323,165 @@ def find_some_leaf_region(region: Union[Block, GraphRegion], node_blacklist, og_
     return None
 
 
+def find_function_start_region(src_top_region: GraphRegion) -> Optional[GraphRegion]:
+    """
+    Finds a region, recursively, that has a function start node in it. A function start node
+    is a node that has a statement that is a Nop with type FUNC_START.
+    """
+    if not isinstance(src_top_region, GraphRegion):
+        return None
+
+    for node in src_top_region.graph.nodes:
+        if isinstance(node, GraphRegion):
+            has_func_start = node_is_function_start(node.head)
+            if has_func_start:
+                return node
+
+            matching_region = find_function_start_region(node)
+            if matching_region is not None:
+                return matching_region
+
+    return None
+
+
+def find_matching_source_region(
+    dec_r_head, dec_r_cfg, src_regions, src_cfg, src_nodes, dec_line_to_addr_map, src_addr_to_line_map
+) -> Tuple[Optional[GraphRegion], bool]:
+    """
+    :return (matching_src_region, redo_structuring)
+    """
+
+    # first do a sanity check to see if the dec head is a FUNCTION_START node, which can speedup analysis
+    dec_head_is_func_start = node_is_function_start(dec_r_head)
+    if dec_head_is_func_start:
+        best_match = find_function_start_region(src_regions)
+        if best_match is not None:
+            return best_match, True
+
+    # map the decompilation line to an address (reported by the decompiler
+    addrs = dec_line_to_addr_map.get(dec_r_head.addr, None)
+    if not addrs:
+        # quick check if you can find the line in the addr map in a proximity
+        up_addrs = dec_line_to_addr_map.get(dec_r_head.addr - 1, None)
+        down_addrs = dec_line_to_addr_map.get(dec_r_head.addr + 1, None)
+        if not up_addrs and not down_addrs:
+            l.debug(f"Unable to find any line-addr map for region head {dec_r_head.addr}! Skipping...")
+            return None, True
+
+        addrs = up_addrs if up_addrs else down_addrs
+
+    all_lines = set(
+        itertools.chain.from_iterable(
+            [src_addr_to_line_map[addr] for addr in addrs if addr in src_addr_to_line_map]
+        )
+    )
+    lines_in_src = set(filter(lambda x: x in src_nodes, all_lines))
+
+    # We were unable to find a real region start, probably because a node got consumed
+    if not lines_in_src:
+        lines_in_src = find_containing_block_addrs(src_cfg, all_lines)
+        if not lines_in_src and addrs:
+            # If we still have nothing, walk backwards!
+            for i in range(1, 0x14):
+                all_lines = set(
+                    itertools.chain.from_iterable(
+                        [src_addr_to_line_map[addr - i] for addr in addrs if addr - i in src_addr_to_line_map]
+                    )
+                )
+                lines_in_src = set(filter(lambda x: x in src_nodes, all_lines))
+                if lines_in_src:
+                    break
+
+    lines_in_src = sorted(lines_in_src)
+    matching_src_regions = list(find_matching_regions_with_lines(src_regions, lines_in_src))
+    if not matching_src_regions:
+        l.debug(f"Unable to find a pairing region for {dec_r_head.addr}: no src addrs found")
+        return None, False
+
+    #
+    # try to find the base matching region
+    #
+
+    # gather sizes
+    matches_by_size = {}
+    lowest_size = 10000
+    for src_region in matching_src_regions:
+        src_block_region = expand_region_to_block_graph(src_region, src_cfg)
+        src_r_head = src_region.head
+        size_diff = abs(len(src_block_region.nodes) - len(dec_r_cfg.nodes))
+        matches_by_size[src_r_head] = (src_region, size_diff)
+        if size_diff < lowest_size:
+            lowest_size = size_diff
+
+    # filter out the ones that are too big
+    matching_src_regions = list(filter(lambda x: x[1][1] <= lowest_size, matches_by_size.items()))
+    if not matching_src_regions:
+        l.debug(f"Unable to find a pairing region for {dec_r_head.addr}")
+        return None, False
+
+    # if we have more than one, tie break with statement size
+    best_match = None
+    if len(matching_src_regions) > 1:
+        smallest_stmt_size = 10000
+        for (head, (region, size)) in matching_src_regions:
+            if not isinstance(head, Block):
+                continue
+
+            has_merged_region = isinstance(head.statements[0], MergedRegionStart)
+            if len(head.statements) < smallest_stmt_size:
+                smallest_stmt_size = len(head.statements)
+                best_match = region
+
+            if has_merged_region:
+                best_match = region
+                break
+
+    if best_match is None:
+        best_match = matching_src_regions[0][1][0]
+
+    # if we matched our decompilation to source and the head is a function start
+    # than we likly made a mistake in approximation of matches
+    #if not dec_head_is_func_start and node_is_function_start(best_match.head):
+    #    return None, False
+
+    return best_match, True
+
+
+def fast_switch_region_ged(expanded_dec_r_graph, expanded_src_r_graph):
+    """
+    The intuition behind this is that in the event we know we are matching two switches across two
+    graphs, we know all the first-level children of the graph going to be the same and their parent is the same.
+    Thus, we can eliminate all (first_parent, childN) edges. Now all we have left is:
+    1. Diff in # of cases between both switches (nodes)
+    2. Diff in case successors (edges)
+
+    In most cases, this will be a very small number of edits. We can simply approximate it by counting # of
+    node and edge differences since those will make up all of the difference in the exit of the region.
+    """
+
+    return abs(len(expanded_dec_r_graph.nodes) - len(expanded_src_r_graph.nodes)) + abs(len(expanded_dec_r_graph.edges) - len(expanded_src_r_graph.edges))
+
+
+def is_switch_region(expanded_region_graph: nx.DiGraph):
+    if expanded_region_graph is None:
+        return False
+
+    region_heads = [node for node in expanded_region_graph.nodes if expanded_region_graph.in_degree(node) == 0]
+    if len(region_heads) != 1:
+        return False
+
+    region_head = region_heads[0]
+    return expanded_region_graph.out_degree(region_head) > 3
+
+
 def cfg_edit_distance(
-        dec_cfg: nx.DiGraph,
-        src_cfg: nx.DiGraph,
-        dec_line_to_addr_map: Dict,
-        src_addr_to_line_map: Dict,
-        max_region_collapse=200,
-        max_region_estimates=3,
-        check_upperbound_approx=True,
+    dec_cfg: nx.DiGraph,
+    src_cfg: nx.DiGraph,
+    dec_line_to_addr_map: Dict,
+    src_addr_to_line_map: Dict,
+    max_region_collapse=200,
+    max_region_estimates=3,
+    check_upperbound_approx=False,
 ):
     """
     src_addr_to_line_map[address] = set(line1, line2, ...)
@@ -286,7 +498,12 @@ def cfg_edit_distance(
     cfged_score = 0
     curr_region_collapse = 0
     curr_region_estimates = 0
+
+    # will always be set on the first iteration since redo_structuring is True
+    src_regions, dec_regions = None, None
+    src_nodes, dec_nodes = {}, {}
     redo_structuring = True
+
     unable_to_approx = False
     region_blacklist = set()
 
@@ -325,10 +542,14 @@ def cfg_edit_distance(
             save_as_png(src_cfg, Path(f"./src_cfg_{curr_region_collapse}.png"))
             save_as_png(dec_cfg, Path(f"./dec_cfg_{curr_region_collapse}.png"))
 
+        #
+        # Find a tail region pair across both graphs
+        #
+
         # Now that you have regions we want to iteratively enter the lower region we can find on one graph
         # then find that same region on the other graph, then do a graph edit distance. In this case
         # we start with the src cfg
-        dec_region = find_some_leaf_region(dec_regions, region_blacklist, dec_cfg)
+        dec_region = find_some_tail_region(dec_regions, region_blacklist, dec_cfg)
         if dec_region is None:
             dec_r_head, dec_r_cfg = None, None
         elif isinstance(dec_region, Block):
@@ -347,120 +568,61 @@ def cfg_edit_distance(
             cfged_score += score
             break
 
-        # map the decompilation line to an address (reported by the decompiler
-        addrs = dec_line_to_addr_map.get(dec_r_head.addr, None)
-        if not addrs:
-            # quick check if you can find the line in the addr map in a proximity
-            up_addrs = dec_line_to_addr_map.get(dec_r_head.addr - 1, None)
-            down_addrs = dec_line_to_addr_map.get(dec_r_head.addr + 1, None)
-            if not up_addrs and not down_addrs:
-                l.debug(f"Unable to find any line-addr map for region head {dec_r_head.addr}! Skipping...")
-                region_blacklist.add(dec_r_head.addr)
-                continue
-
-            addrs = up_addrs if up_addrs else down_addrs
-
-        all_lines = set(
-            itertools.chain.from_iterable(
-                [src_addr_to_line_map[addr] for addr in addrs if addr in src_addr_to_line_map]
-            )
+        best_match, redo_structuring = find_matching_source_region(
+            dec_r_head, dec_r_cfg, src_regions, src_cfg, src_nodes, dec_line_to_addr_map, src_addr_to_line_map
         )
-        lines_in_src = set(filter(lambda x: x in src_nodes, all_lines))
-
-        # We were unable to find a real region start, probably because a node got consumed
-        if not lines_in_src:
-            lines_in_src = find_containing_block_addrs(src_cfg, all_lines)
-            if not lines_in_src and addrs:
-                # If we still have nothing, walk backwards!
-                for i in range(1, 0x14):
-                    all_lines = set(
-                        itertools.chain.from_iterable(
-                            [src_addr_to_line_map[addr-i] for addr in addrs if addr-i in src_addr_to_line_map]
-                        )
-                    )
-                    lines_in_src = set(filter(lambda x: x in src_nodes, all_lines))
-                    if lines_in_src:
-                        break
-
-
-        lines_in_src = sorted(lines_in_src)
-        matching_src_regions = list(find_matching_regions_with_lines(src_regions, lines_in_src))
-        if not matching_src_regions:
-            region_blacklist.add(dec_r_head.addr)
-            redo_structuring = False
+        if redo_structuring:
             curr_region_collapse += 1
-            l.debug(f"Unable to find a pairing region for {dec_r_head.addr}: no src addrs found")
-            continue
-
-        #
-        # try to find the base matching region
-        #
-
-        # gather sizes
-        matches_by_size = {}
-        lowest_size = 10000
-        for src_region in matching_src_regions:
-            src_block_region = expand_region_to_block_graph(src_region, src_cfg)
-            src_r_head = src_region.head
-            size_diff = abs(len(src_block_region.nodes) - len(dec_r_cfg.nodes))
-            matches_by_size[src_r_head] = (src_region, size_diff)
-            if size_diff < lowest_size:
-                lowest_size = size_diff
-
-        # filter out the ones that are too big
-        matching_src_regions = list(filter(lambda x: x[1][1] <= lowest_size, matches_by_size.items()))
-        if not matching_src_regions:
+        if best_match is None:
             region_blacklist.add(dec_r_head.addr)
-            redo_structuring = False
-            curr_region_collapse += 1
-            l.debug(f"Unable to find a pairing region for {dec_r_head.addr}")
             continue
 
-        # if we have more than one, tie break with statement size
-        best_match = None
-        if len(matching_src_regions) > 1:
-            smallest_stmt_size = 10000
-            for (head, (region, size)) in matching_src_regions:
-                if not isinstance(head, Block):
-                    continue
-
-                has_merged_region = isinstance(head.statements[0], MergedRegionStart)
-                if len(head.statements) < smallest_stmt_size:
-                    smallest_stmt_size = len(head.statements)
-                    best_match = region
-
-                if has_merged_region:
-                    best_match = region
-                    break
-
-        if best_match is None:
-            best_match = matching_src_regions[0][1][0]
-
-
         l.debug(f"Collapsing (Dec, Src) region pair: {(dec_r_head, best_match.head)}")
+
         #
-        # compute GED of the expanded region
+        # compute GED of the expanded-matched tail regions
         #
 
         src_r_cfg = expand_region_to_block_graph(best_match, src_cfg)
+        expanded_src_graph, src_successor = expand_region_to_successor_block_graph(best_match, src_cfg)
+        expanded_dec_graph, dec_successor = expand_region_to_successor_block_graph(dec_region, dec_cfg)
 
-        dec_r_size, src_r_size = len(dec_r_cfg.nodes), len(src_r_cfg.nodes)
-        if dec_r_size > MAX_NODES_FOR_EXACT_GED or src_r_size > MAX_NODES_FOR_EXACT_GED:
-            l.debug(f"Encountered a region too large (dec,src): ({len(dec_r_cfg.nodes), len(src_r_cfg.nodes)} nodes) for an exact score, estimating it...")
-            size_diff = abs(dec_r_size - src_r_size)
-            curr_region_collapse += 1
-            if size_diff > dec_r_size*2 or size_diff > src_r_size*2:
-                l.debug(f"Difference in regions size too large to approximate, skipping for now...")
+        bad_successor_case = expanded_src_graph is None or expanded_dec_graph is None
+        if not bad_successor_case:
+            dec_size, src_size = len(expanded_dec_graph.nodes), len(expanded_src_graph.nodes)
+        else:
+            dec_size, src_size = len(dec_r_cfg.nodes), len(src_r_cfg.nodes)
+
+        too_large_for_exact = dec_size > MAX_NODES_FOR_EXACT_GED or src_size > MAX_NODES_FOR_EXACT_GED
+        # a heuristic to see if the size difference is too large to approximate, which will cause a skip
+        if too_large_for_exact:
+            size_diff = abs(dec_size - src_size)
+            if size_diff > dec_size*2 or size_diff > src_size*2:
+                l.debug(f"Difference in regions size too large to approximate (Dec, Src): ({dec_size}, {src_size}), skipping for now...")
                 region_blacklist.add(dec_r_head.addr)
                 redo_structuring = False
                 continue
+            else:
+                curr_region_estimates += 1
 
-            #if curr_region_estimates >= max_region_estimates:
-            #    l.warning(f"Exceeded the max region GED approximizaition limit. This function can't be computed.")
-            #    return -1
-            curr_region_estimates += 1
+        # In most graph expasions of a region, the region should have a single successor and be moderately sized.
+        # In the event this is not true, we can generate highly innacurate GED scores because we rely on GED
+        # approximation of this larger/broken region. To mitigate this, we can special case scenarios which cause
+        # the most problems
+        #
+        # 1. The region is a switch statement, which means its region is huge but actually quite simple
+        switch_region_case = is_switch_region(expanded_src_graph) and is_switch_region(expanded_dec_graph) and too_large_for_exact
+        # 2. The regions has multiple successors (bad_successor_case)
+
+        if switch_region_case:
+            l.debug("Special Case Detected: Switch Region. Using Fast Switch GED...")
+            distance = fast_switch_region_ged(expanded_dec_graph, expanded_src_graph)
+        elif bad_successor_case:
+            l.debug("Special Case Detected: Multi-Successor Region. Using edge-diffs for approx...")
+            distance = graph_edit_distance_core_analysis(dec_r_cfg, src_r_cfg, with_timeout=4)
+        else:
+            distance = graph_edit_distance_core_analysis(expanded_dec_graph, expanded_src_graph, with_timeout=4)
 
-        distance = graph_edit_distance_core_analysis(dec_r_cfg, src_r_cfg, with_timeout=4)
         if distance is None:
             l.debug(f"Unable to compute the GED of the region, skipping...")
             region_blacklist.add(dec_r_head.addr)
@@ -484,10 +646,13 @@ def cfg_edit_distance(
             expand_region_to_block_graph(dec_region, dec_cfg) if not isinstance(dec_region, Block) else dec_region,
             expand_region_head_to_block(dec_region) if not isinstance(dec_region, Block) else dec_region
         )
-        edge_diff = find_dst_mismatches(extra_dec_edges, extra_src_edges, dec_line_to_addr_map, src_addr_to_line_map)
-        if edge_diff:
-            l.debug(f"In/Out Edge Diff: {edge_diff}")
-            cfged_score += edge_diff
+
+        # extra edge diffs are only needed in the event we can't use a normally expanded region graph
+        if bad_successor_case:
+            edge_diff = find_dst_mismatches(extra_dec_edges, extra_src_edges, dec_line_to_addr_map, src_addr_to_line_map)
+            if edge_diff:
+                l.debug(f"In/Out Edge Diff: {edge_diff}")
+                cfged_score += edge_diff
 
         if len(dec_cfg.nodes) <= 1 or len(src_cfg.nodes) <= 1:
             distance = graph_edit_distance_core_analysis(dec_cfg, src_cfg, with_timeout=10)
@@ -499,7 +664,6 @@ def cfg_edit_distance(
             break
 
         region_blacklist = set()
-        curr_region_collapse += 1
         redo_structuring = True
 
     l.debug(f"{bcolors.WARNING}Final CFGED Score: {bcolors.BOLD}{cfged_score}{bcolors.ENDC}")
diff --git a/sailreval/joern/cfg/ged.py b/sailreval/joern/cfg/ged.py
index fcb2604..61cbb83 100644
--- a/sailreval/joern/cfg/ged.py
+++ b/sailreval/joern/cfg/ged.py
@@ -8,11 +8,11 @@ from .jil.block import Block
 from .jil.statement import (
     Statement, Assignment, Compare, Call, Nop
 )
-from .utils import find_function_root_node
+from .utils import find_function_root_node, node_is_function_start, node_is_function_end
 from sailreval.utils import timeout
 
 _l = logging.getLogger(__name__)
-MAX_NODES_FOR_EXACT_GED = 10
+MAX_NODES_FOR_EXACT_GED = 12
 INVALID_CHOICE_PENALTY = 100000
 
 #
@@ -21,12 +21,20 @@ INVALID_CHOICE_PENALTY = 100000
 
 
 def _collect_graph_roots(g1, g2):
+    # first, depend on the function start node
     g1_start, g2_start = find_function_root_node(g1), find_function_root_node(g2)
     if g1_start is not None and g2_start is not None:
         roots = (g1_start, g2_start,)
     else:
         roots = None
 
+    # second attempt, use predecessors
+    if roots is None:
+        g1_starts = list(node for node in g1.nodes if len(list(g1.predecessors(node))) == 0)
+        g2_starts = list(node for node in g2.nodes if len(list(g2.predecessors(node))) == 0)
+        if len(g1_starts) == 1 == len(g2_starts):
+            roots = (g1_starts[0], g2_starts[0],)
+
     return roots
 
 
@@ -63,10 +71,12 @@ def graph_edit_distance_core_analysis(
 ):
     roots = _collect_graph_roots(g1, g2) if is_cfg else None
 
-    # edge insertion cost
+    # edge edit cost
     def _edge_ins_cost(*args): return 1
-    # node deletion cost
+    def _edge_sub_cost(*args): return 0
+    # node edit cost
     def _node_del_cost(*args): return 1
+    def _node_sub_cost(*args): return 0
 
     if is_cfg:
         def _edge_ins_cost(*args):
@@ -78,14 +88,10 @@ def graph_edit_distance_core_analysis(
             src = attrs.get('src', None)
             dst = attrs.get('dst', None)
             if penalize_root_exit_edits:
-                if src and src.statements:
-                    last_stmt = src.statements[-1]
-                    if isinstance(last_stmt, Nop) and last_stmt.type == Nop.FUNC_END and src is not dst:
-                        return INVALID_CHOICE_PENALTY
-                elif dst and dst.statements:
-                    first_stmt = dst.statements[0]
-                    if isinstance(first_stmt, Nop) and first_stmt.type == Nop.FUNC_START and dst is not src:
-                        return INVALID_CHOICE_PENALTY
+                if src and src is not dst and node_is_function_end(src):
+                    return INVALID_CHOICE_PENALTY
+                elif dst and dst is not src and node_is_function_start(dst):
+                    return INVALID_CHOICE_PENALTY
 
             return 1
 
@@ -94,32 +100,47 @@ def graph_edit_distance_core_analysis(
             Makes it illegal to delete function start nodes or end nodes
             """
             node = args[0].get('node', None)
-            if penalize_root_exit_edits and node and node.statements:
-                first_stmt = node.statements[0]
-                last_stmt = node.statements[-1]
-                if isinstance(first_stmt, Nop) and first_stmt.type == Nop.FUNC_START:
-                    return INVALID_CHOICE_PENALTY
-                elif isinstance(last_stmt, Nop) and last_stmt.type == Nop.FUNC_END:
+            if penalize_root_exit_edits:
+                if node_is_function_start(node) or node_is_function_end(node):
                     return INVALID_CHOICE_PENALTY
 
             return 1
 
+        def _node_sub_cost(*args):
+            """
+            Makes it illegal to delete function start nodes or end nodes
+            """
+            node_attrs = args[:2]
+            n1, n2 = node_attrs[0].get('node', None), node_attrs[1].get('node', None)
+            if penalize_root_exit_edits:
+                if (node_is_function_start(n1) or node_is_function_end(n1)) and n2 is None:
+                    return INVALID_CHOICE_PENALTY
+
+            return 0
+
     if exact_score or upperbound_approx:
         try:
             with timeout(seconds=with_timeout):
                 if upperbound_approx:
-                    dist = next(nx.optimize_graph_edit_distance(g1, g2, node_del_cost=_node_del_cost, edge_ins_cost=_edge_ins_cost))
+                    dist = next(nx.optimize_graph_edit_distance(
+                        g1, g2, node_del_cost=_node_del_cost, edge_ins_cost=_edge_ins_cost,
+                        node_subst_cost=_node_sub_cost, edge_subst_cost=_edge_sub_cost,
+                    ))
                 else:
-                    dist = nx.graph_edit_distance(g1, g2, roots=roots, node_del_cost=_node_del_cost, edge_ins_cost=_edge_ins_cost)
+                    dist = nx.graph_edit_distance(
+                        g1, g2, roots=roots, node_del_cost=_node_del_cost, edge_ins_cost=_edge_ins_cost,
+                        node_subst_cost=_node_sub_cost, edge_subst_cost=_edge_sub_cost,
+                    )
         except TimeoutError:
             dist = None
     else:
         dist = nx.graph_edit_distance(
-            g1, g2, roots=roots, node_del_cost=_node_del_cost, edge_ins_cost=_edge_ins_cost, timeout=with_timeout
+            g1, g2, roots=roots, node_del_cost=_node_del_cost, edge_ins_cost=_edge_ins_cost, timeout=with_timeout,
+            node_subst_cost=_node_sub_cost, edge_subst_cost=_edge_sub_cost,
         )
 
     # sometimes the score can be computed wrong, which we can fix with a recompute ONCE
-    if dist is not None and dist > INVALID_CHOICE_PENALTY and recover_on_invalid_edits:
+    if dist is not None and dist >= INVALID_CHOICE_PENALTY and recover_on_invalid_edits:
         dist = graph_edit_distance_core_analysis(
             g1, g2, is_cfg=is_cfg, upperbound_approx=upperbound_approx, exact_score=exact_score,
             with_timeout=with_timeout, penalize_root_exit_edits=False, recover_on_invalid_edits=False
diff --git a/sailreval/joern/cfg/utils.py b/sailreval/joern/cfg/utils.py
index db4970f..b24218a 100644
--- a/sailreval/joern/cfg/utils.py
+++ b/sailreval/joern/cfg/utils.py
@@ -4,16 +4,17 @@ import shutil
 from tempfile import TemporaryDirectory
 import logging
 import os
-from typing import Dict
+from typing import Dict, Union
 
 import networkx
 from networkx import Graph, DiGraph
 
 from sailreval.utils import WorkDirContext, bcolors
+from .graph_region import GraphRegion
 from .. import JOERN_EXPORT_PATH, JOERN_PARSE_PATH
 from .jil.lifter import lift_graph
 from .jil.block import Block
-from .jil.statement import Nop, Statement
+from .jil.statement import Nop, Statement, MergedRegionStart
 from ...utils.binary_debug_info import read_line_maps
 
 import networkx as nx
@@ -29,10 +30,60 @@ def addr_to_node_map(graph):
     }
 
 
+def expand_region_head_to_block(region: GraphRegion):
+    region_head = region.head
+    if isinstance(region_head, Block):
+        return region_head
+
+    if isinstance(region_head, GraphRegion):
+        return expand_region_head_to_block(region_head)
+
+    raise ValueError(f"Invalid region head type {type(region_head)}")
+
+
+def node_is_function_end(node: Union[Block, GraphRegion]):
+    if node is None:
+        return False
+
+    node = expand_region_head_to_block(node) if isinstance(node, GraphRegion) else node
+    if not node.statements:
+        return False
+
+    last_stmt = node.statements[-1]
+    first_stmt = node.statements[0]
+    if isinstance(last_stmt, Nop) and last_stmt.type == Nop.FUNC_END:
+        return True
+    elif isinstance(first_stmt, MergedRegionStart):
+        for stmt in node.statements:
+            if isinstance(stmt, Nop) and stmt.type == Nop.FUNC_END:
+                return True
+    else:
+        return False
+
+
+def node_is_function_start(node: Union[Block, GraphRegion]):
+    if node is None:
+        return False
+
+    node = expand_region_head_to_block(node) if isinstance(node, GraphRegion) else node
+    if not node.statements:
+        return False
+
+    first_stmt = node.statements[0]
+    if isinstance(first_stmt, MergedRegionStart):
+        for stmt in node.statements:
+            if isinstance(stmt, Nop) and stmt.type == Nop.FUNC_START:
+                return True
+    elif isinstance(first_stmt, Nop) and first_stmt.type == Nop.FUNC_START:
+        return True
+    else:
+        return False
+
+
+
 def find_function_root_node(graph: nx.DiGraph):
     for node in graph.nodes:
-        first_stmt = node.statements[0]
-        if isinstance(first_stmt, Nop) and first_stmt.type == Nop.FUNC_START:
+        if node_is_function_start(node):
             return node
 
     return None
diff --git a/sailreval/metrics/ged_to_source.py b/sailreval/metrics/ged_to_source.py
index 4fbc6f6..4b5427c 100644
--- a/sailreval/metrics/ged_to_source.py
+++ b/sailreval/metrics/ged_to_source.py
@@ -32,13 +32,14 @@ def ged_exact_score(
     """
     Computes the exact GED for a given function.
     """
+    # skip source
     if decompiler == "source":
         return float(0)
     source_cfg, dec_cfg = _verify_has_valid_graphs(func_name, client, source_cfgs, dec_cfgs, decompiler, binary_path)
     if source_cfg is None or dec_cfg is None:
         return None
 
-    return ged_exact(source_cfg, dec_cfg)
+    return ged_exact(dec_cfg, source_cfg)
 
 
 def ged_upperbound_score(
diff --git a/scripts/run_cfged_on_file.py b/scripts/run_cfged_on_file.py
index 5e38ff0..c92a47f 100755
--- a/scripts/run_cfged_on_file.py
+++ b/scripts/run_cfged_on_file.py
@@ -5,6 +5,7 @@ from pathlib import Path
 
 from sailreval import SAILR_DECOMPILERS, ALL_DECOMPILERS
 from sailreval.metrics.ged_to_source import compute_cfg_edit_distance, ged_upperbound_score
+from sailreval.joern.cfg.ged import ged_exact
 from sailreval.joern.cfg.utils import cfgs_from_source, correct_source_cfg_addrs, save_as_png
 
 
@@ -28,9 +29,15 @@ if __name__ == "__main__":
     parser.add_argument(
         '--save-png', help="Save a PNG of the CFG for source and decompilation", action="store_true", default=False
     )
+    parser.add_argument(
+        '--debug', help="Output DEBUG info and save region-collapsed CFGs", action="store_true", default=False
+    )
 
     args = parser.parse_args()
     dec_dir_path = Path(args.dec_dir_path).expanduser().absolute()
+    if args.debug:
+        from sailreval.joern.cfg.cfged import toggle_debug
+        toggle_debug()
 
     basename = args.basename
     function = args.func
@@ -57,6 +64,12 @@ if __name__ == "__main__":
         func_cfg = dec_cfgs[function]
         dist = compute_cfg_edit_distance(func_cfg, source_cfgs[function], function, binary_path, decompiler)
         upper_ged = ged_upperbound_score(function, None, source_cfgs=source_cfgs, dec_cfgs=dec_cfgs)
-        print(f"Decompiler: {decompiler} Target: {basename} - {function} | CFGED: {dist} | O-GED: {upper_ged}")
+        exact_score_string = ""
+        if len(func_cfg.nodes) < 12:
+            exact_score = ged_exact(func_cfg, source_cfgs[function])
+            exact_score_string = f" | Exact: {exact_score}"
+
+
+        print(f"Decompiler: {decompiler} Target: {basename} - {function} | CFGED: {dist} | O-GED: {upper_ged}{exact_score_string}")
         if args.save_png:
             save_as_png(func_cfg, dec_dir_path / f"{decompiler}_{basename}_{function}.png")
